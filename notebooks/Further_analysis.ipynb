{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import useful packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basics\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.stats import mode\n",
    "import base64\n",
    "import io\n",
    "import os\n",
    "import requests\n",
    "\n",
    "#sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, mean_squared_error, recall_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>e</th>\n",
       "      <th>AC</th>\n",
       "      <th>FM</th>\n",
       "      <th>UC</th>\n",
       "      <th>DL</th>\n",
       "      <th>DS</th>\n",
       "      <th>DP</th>\n",
       "      <th>DR</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>...</th>\n",
       "      <th>E</th>\n",
       "      <th>AD</th>\n",
       "      <th>DE</th>\n",
       "      <th>LD</th>\n",
       "      <th>FS</th>\n",
       "      <th>SUSP</th>\n",
       "      <th>Unnamed: 42</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>Unnamed: 44</th>\n",
       "      <th>NSP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>118</td>\n",
       "      <td>617</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>2</td>\n",
       "      <td>525</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>734</td>\n",
       "      <td>1789</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856</th>\n",
       "      <td>552</td>\n",
       "      <td>1500</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>0</td>\n",
       "      <td>1199</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        b     e  AC  FM  UC  DL  DS  DP  DR  Unnamed: 9  ...  E  AD  DE  LD  \\\n",
       "352   118   617   0  11   0   0   0   0   0         NaN  ... -1  -1  -1  -1   \n",
       "2050    2   525   0   1   1   0   0   0   0         NaN  ... -1  -1  -1  -1   \n",
       "1860  734  1789  16   0   4   0   0   0   0         NaN  ... -1  -1  -1  -1   \n",
       "1856  552  1500  13   0   4   0   0   0   0         NaN  ... -1  -1  -1  -1   \n",
       "335     0  1199   0   3   0   0   0   0   0         NaN  ... -1  -1  -1  -1   \n",
       "\n",
       "      FS  SUSP  Unnamed: 42  CLASS  Unnamed: 44  NSP  \n",
       "352    1    -1          NaN      9          NaN    3  \n",
       "2050  -1    -1          NaN      3          NaN    1  \n",
       "1860  -1    -1          NaN      2          NaN    1  \n",
       "1856  -1    -1          NaN      2          NaN    1  \n",
       "335    1    -1          NaN      9          NaN    3  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/Users/erikgutierrezduthiers/Desktop/CW_Intro_AI/data/\"\n",
    "filename = \"CTG.xls\"\n",
    "\n",
    "df = pd.read_excel(path+filename, sheet_name = \"Data\",header=1)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.head()\n",
    "# shape: (891, 12) assdsd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data description**:\n",
    "\n",
    "* 2126 fetal cardiotocograms (CTGs).\n",
    "* CTGs classified by: \n",
    "    * morphologic pattern (A, B, C....) - 10-class experiment\n",
    "    * fetal state (N, S, P) - 3-class experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LB</th>\n",
       "      <th>AC</th>\n",
       "      <th>FM</th>\n",
       "      <th>UC</th>\n",
       "      <th>DL</th>\n",
       "      <th>DP</th>\n",
       "      <th>ASTV</th>\n",
       "      <th>MSTV</th>\n",
       "      <th>ALTV</th>\n",
       "      <th>MLTV</th>\n",
       "      <th>Width</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Nmax</th>\n",
       "      <th>Nzeros</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Tendency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>0.2</td>\n",
       "      <td>86</td>\n",
       "      <td>3.4</td>\n",
       "      <td>8</td>\n",
       "      <td>136</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>140</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>1.9</td>\n",
       "      <td>16</td>\n",
       "      <td>4.1</td>\n",
       "      <td>20</td>\n",
       "      <td>119</td>\n",
       "      <td>139</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>127</td>\n",
       "      <td>131</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>138</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>49</td>\n",
       "      <td>122</td>\n",
       "      <td>171</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>148</td>\n",
       "      <td>149</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856</th>\n",
       "      <td>138</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>49</td>\n",
       "      <td>122</td>\n",
       "      <td>171</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>148</td>\n",
       "      <td>149</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>0.2</td>\n",
       "      <td>67</td>\n",
       "      <td>3.9</td>\n",
       "      <td>13</td>\n",
       "      <td>137</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>144</td>\n",
       "      <td>146</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LB  AC  FM  UC  DL  DP  ASTV  MSTV  ALTV  MLTV  Width  Min  Max  Nmax  \\\n",
       "352   140   0  11   0   0   0    78   0.2    86   3.4      8  136  144     1   \n",
       "2050  128   0   1   1   0   0    70   1.9    16   4.1     20  119  139     2   \n",
       "1860  138  16   0   4   0   0    51   0.9     0   1.9     49  122  171     2   \n",
       "1856  138  13   0   4   0   0    51   1.1     0   2.1     49  122  171     3   \n",
       "335   146   0   3   0   0   0    81   0.2    67   3.9     13  137  150     1   \n",
       "\n",
       "      Nzeros  Mode  Mean  Median  Variance  Tendency  \n",
       "352        0   141   140     141         0         0  \n",
       "2050       0   130   127     131         1         0  \n",
       "1860       0   147   148     149         5         0  \n",
       "1856       0   148   148     149         6         0  \n",
       "335        0   146   144     146         1         0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns to be considered in the dataset\n",
    "columns = [\"LB\", \"AC\", \"FM\", \"UC\", \"DL\", \"DP\", \n",
    "           \"ASTV\", \"MSTV\", \"ALTV\", \"MLTV\", \"Width\", \"Min\", \n",
    "           \"Max\", \"Nmax\", \"Nzeros\", \"Mode\", \"Mean\", \"Median\", \"Variance\", \"Tendency\"]\n",
    "\n",
    "#Prepare X and y\n",
    "X = df[columns]\n",
    "y = df[\"NSP\"]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2126, 20)\n",
      "(2126,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Standardization \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LB</th>\n",
       "      <th>AC</th>\n",
       "      <th>FM</th>\n",
       "      <th>UC</th>\n",
       "      <th>DL</th>\n",
       "      <th>DP</th>\n",
       "      <th>ASTV</th>\n",
       "      <th>MSTV</th>\n",
       "      <th>ALTV</th>\n",
       "      <th>MLTV</th>\n",
       "      <th>Width</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Nmax</th>\n",
       "      <th>Nzeros</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Tendency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.680604</td>\n",
       "      <td>-0.764740</td>\n",
       "      <td>0.101267</td>\n",
       "      <td>-1.285798</td>\n",
       "      <td>-0.628375</td>\n",
       "      <td>-0.27153</td>\n",
       "      <td>1.804078</td>\n",
       "      <td>-1.282833</td>\n",
       "      <td>4.140444</td>\n",
       "      <td>-0.850843</td>\n",
       "      <td>-1.603375</td>\n",
       "      <td>1.435392</td>\n",
       "      <td>-1.116245</td>\n",
       "      <td>-1.040530</td>\n",
       "      <td>-0.458444</td>\n",
       "      <td>0.216638</td>\n",
       "      <td>0.345702</td>\n",
       "      <td>0.201179</td>\n",
       "      <td>-0.649208</td>\n",
       "      <td>-0.524526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.539090</td>\n",
       "      <td>-0.764740</td>\n",
       "      <td>-0.168154</td>\n",
       "      <td>-0.934480</td>\n",
       "      <td>-0.628375</td>\n",
       "      <td>-0.27153</td>\n",
       "      <td>1.338658</td>\n",
       "      <td>0.642349</td>\n",
       "      <td>0.334556</td>\n",
       "      <td>-0.726441</td>\n",
       "      <td>-1.295261</td>\n",
       "      <td>0.860159</td>\n",
       "      <td>-1.394953</td>\n",
       "      <td>-0.701397</td>\n",
       "      <td>-0.458444</td>\n",
       "      <td>-0.455018</td>\n",
       "      <td>-0.488170</td>\n",
       "      <td>-0.490232</td>\n",
       "      <td>-0.614691</td>\n",
       "      <td>-0.524526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.477322</td>\n",
       "      <td>3.729626</td>\n",
       "      <td>-0.195096</td>\n",
       "      <td>0.119475</td>\n",
       "      <td>-0.628375</td>\n",
       "      <td>-0.27153</td>\n",
       "      <td>0.233285</td>\n",
       "      <td>-0.490111</td>\n",
       "      <td>-0.535361</td>\n",
       "      <td>-1.117419</td>\n",
       "      <td>-0.550650</td>\n",
       "      <td>0.961671</td>\n",
       "      <td>0.388775</td>\n",
       "      <td>-0.701397</td>\n",
       "      <td>-0.458444</td>\n",
       "      <td>0.582996</td>\n",
       "      <td>0.858853</td>\n",
       "      <td>0.754307</td>\n",
       "      <td>-0.476621</td>\n",
       "      <td>-0.524526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.477322</td>\n",
       "      <td>2.886933</td>\n",
       "      <td>-0.195096</td>\n",
       "      <td>0.119475</td>\n",
       "      <td>-0.628375</td>\n",
       "      <td>-0.27153</td>\n",
       "      <td>0.233285</td>\n",
       "      <td>-0.263619</td>\n",
       "      <td>-0.535361</td>\n",
       "      <td>-1.081875</td>\n",
       "      <td>-0.550650</td>\n",
       "      <td>0.961671</td>\n",
       "      <td>0.388775</td>\n",
       "      <td>-0.362263</td>\n",
       "      <td>-0.458444</td>\n",
       "      <td>0.644055</td>\n",
       "      <td>0.858853</td>\n",
       "      <td>0.754307</td>\n",
       "      <td>-0.442103</td>\n",
       "      <td>-0.524526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.290451</td>\n",
       "      <td>-0.764740</td>\n",
       "      <td>-0.114270</td>\n",
       "      <td>-1.285798</td>\n",
       "      <td>-0.628375</td>\n",
       "      <td>-0.27153</td>\n",
       "      <td>1.978610</td>\n",
       "      <td>-1.282833</td>\n",
       "      <td>3.107418</td>\n",
       "      <td>-0.761985</td>\n",
       "      <td>-1.474994</td>\n",
       "      <td>1.469229</td>\n",
       "      <td>-0.781796</td>\n",
       "      <td>-1.040530</td>\n",
       "      <td>-0.458444</td>\n",
       "      <td>0.521936</td>\n",
       "      <td>0.602278</td>\n",
       "      <td>0.546884</td>\n",
       "      <td>-0.614691</td>\n",
       "      <td>-0.524526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         LB        AC        FM        UC        DL       DP      ASTV  \\\n",
       "0  0.680604 -0.764740  0.101267 -1.285798 -0.628375 -0.27153  1.804078   \n",
       "1 -0.539090 -0.764740 -0.168154 -0.934480 -0.628375 -0.27153  1.338658   \n",
       "2  0.477322  3.729626 -0.195096  0.119475 -0.628375 -0.27153  0.233285   \n",
       "3  0.477322  2.886933 -0.195096  0.119475 -0.628375 -0.27153  0.233285   \n",
       "4  1.290451 -0.764740 -0.114270 -1.285798 -0.628375 -0.27153  1.978610   \n",
       "\n",
       "       MSTV      ALTV      MLTV     Width       Min       Max      Nmax  \\\n",
       "0 -1.282833  4.140444 -0.850843 -1.603375  1.435392 -1.116245 -1.040530   \n",
       "1  0.642349  0.334556 -0.726441 -1.295261  0.860159 -1.394953 -0.701397   \n",
       "2 -0.490111 -0.535361 -1.117419 -0.550650  0.961671  0.388775 -0.701397   \n",
       "3 -0.263619 -0.535361 -1.081875 -0.550650  0.961671  0.388775 -0.362263   \n",
       "4 -1.282833  3.107418 -0.761985 -1.474994  1.469229 -0.781796 -1.040530   \n",
       "\n",
       "     Nzeros      Mode      Mean    Median  Variance  Tendency  \n",
       "0 -0.458444  0.216638  0.345702  0.201179 -0.649208 -0.524526  \n",
       "1 -0.458444 -0.455018 -0.488170 -0.490232 -0.614691 -0.524526  \n",
       "2 -0.458444  0.582996  0.858853  0.754307 -0.476621 -0.524526  \n",
       "3 -0.458444  0.644055  0.858853  0.754307 -0.442103 -0.524526  \n",
       "4 -0.458444  0.521936  0.602278  0.546884 -0.614691 -0.524526  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the standar scaler to features\n",
    "sc = StandardScaler()\n",
    "sc.fit(X)\n",
    "X_std = pd.DataFrame(sc.transform(X),columns=columns)\n",
    "X_std.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data standardization is used to minimize the difference in the ranges of the features, ensuring the gradient descent moves smoothly towards the minima and that the steps for gradient descent are updated at the same rate for all the features. However, scaling does not significantly affect our accuracy in our case because our features are within the same range (i.e., 0 - 200).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To treat the class imbalance we use SMOTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=31)\n",
    "\n",
    "X_sm, y_sm = sm.fit_resample(X_std, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Supervised Learning Models \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a class with all the supervised learning models to make evaluating them easier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, mean_squared_error\n",
    "\n",
    "class SLClassifiers(): \n",
    "    \n",
    "    \n",
    "    def __init__(self, X, y): \n",
    "        \n",
    "        self.X = X\n",
    "        self.y = y \n",
    "        \n",
    "    \n",
    "    def confusion_matrix(self, y_pred, y_test, target_labels): \n",
    "        \n",
    "        cm = confusion_matrix(y_pred,y_test, normalize=\"all\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_labels);\n",
    "        disp.plot();\n",
    "        \n",
    "    \n",
    "    def train_test_split(self): \n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(self.X, self.y, train_size=0.8,random_state=35)\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "        \n",
    "    def decision_tree(self): \n",
    "        \n",
    "        X_train, X_test, y_train, y_test = self.train_test_split()\n",
    "        dt = DecisionTreeClassifier(random_state=35)\n",
    "        dt.fit(X_train, y_train)\n",
    "        y_pred = dt.predict(X_test)\n",
    "        print(\"Decision Tree accuracy: %.2f\" % accuracy_score(y_pred,y_test) )\n",
    "        print(\"Decision Tree recall: %.2f\" % recall_score(y_pred,y_test,average=\"macro\") )\n",
    "        #self.confusion_matrix(y_pred, y_test, dt.classes_)\n",
    "        \n",
    "    \n",
    "    def random_forest(self, n_estimators=10, max_depth=None, criterion=\"entropy\"): \n",
    "        \n",
    "        X_train, X_test, y_train, y_test = self.train_test_split()\n",
    "        rf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, criterion=criterion)\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred = rf.predict(X_test)\n",
    "        \n",
    "        print(\"Random Forest accuracy: %.2f\" % accuracy_score(y_pred,y_test) )\n",
    "        print(\"Random Forest recall: %.2f\" % recall_score(y_pred,y_test,average=\"macro\") )\n",
    "        #self.confusion_matrix(y_pred, y_test, rf.classes_)\n",
    "\n",
    "    \n",
    "    def support_vector_machine(self, kernel = \"linear\", C=10000): \n",
    "       \n",
    "        X_train, X_test, y_train, y_test = self.train_test_split()\n",
    "        svm = SVC(kernel=kernel, C=C)\n",
    "        svm.fit(X_train, y_train)\n",
    "        y_pred = svm.predict(X_test)\n",
    "        print(\"Support Vector Machine accuracy: %.2f\" % accuracy_score(y_test, y_pred))\n",
    "        print(\"Support Vector Machine recall: %.2f\" % recall_score(y_pred,y_test,average=\"macro\") )\n",
    "        \n",
    "        #self.confusion_matrix(y_pred, y_test, rf.classes_)\n",
    "        \n",
    "        \n",
    "    def k_nearest_neighbours(self, n=3): \n",
    "    \n",
    "        X_train, X_test, y_train, y_test = self.train_test_split()\n",
    "        knn = KNeighborsClassifier(n_neighbors=n)\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "        print(\"K-Nearest Neighbours accuracy: %.2f\" % accuracy_score(y_pred,y_test) )\n",
    "        print(\"K-Nearest Neighbours recall: %.2f\" % recall_score(y_pred,y_test,average=\"macro\") )\n",
    "        \n",
    "        \n",
    "    def gaussian_naive_bayes(self):\n",
    "       \n",
    "        X_train, X_test, y_train, y_test = self.train_test_split()\n",
    "        gnb = GaussianNB()\n",
    "        gnb.fit(X_train, y_train);\n",
    "        y_pred = gnb.predict(X_test)\n",
    "        print(\"Gaussian Naive Bayes accuracy: %.2f\" % accuracy_score(y_pred,y_test) )\n",
    "        print(\"Gaussian Naive Bayes recall: %.2f\" % recall_score(y_pred,y_test,average=\"macro\") )\n",
    "\n",
    "\n",
    "slc = SLClassifiers(X, y)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us apply all the supervised learning models to our raw data to see how well the classifiers perform.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree accuracy: 0.90\n",
      "Decision Tree recall: 0.84\n",
      "Random Forest accuracy: 0.94\n",
      "Random Forest recall: 0.90\n",
      "Support Vector Machine accuracy: 0.91\n",
      "Support Vector Machine recall: 0.85\n",
      "K-Nearest Neighbours accuracy: 0.88\n",
      "K-Nearest Neighbours recall: 0.82\n",
      "Gaussian Naive Bayes accuracy: 0.80\n",
      "Gaussian Naive Bayes recall: 0.68\n"
     ]
    }
   ],
   "source": [
    "dt = slc.decision_tree()\n",
    "rf = slc.random_forest(n_estimators=100)\n",
    "svm = slc.support_vector_machine()\n",
    "knn = slc.k_nearest_neighbours()\n",
    "gnb = slc.gaussian_naive_bayes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we apply all the supervised learning models to our processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree accuracy: 0.96\n",
      "Decision Tree recall: 0.96\n",
      "Random Forest accuracy: 0.98\n",
      "Random Forest recall: 0.98\n",
      "Support Vector Machine accuracy: 0.90\n",
      "Support Vector Machine recall: 0.90\n",
      "K-Nearest Neighbours accuracy: 0.96\n",
      "K-Nearest Neighbours recall: 0.96\n",
      "Gaussian Naive Bayes accuracy: 0.79\n",
      "Gaussian Naive Bayes recall: 0.81\n"
     ]
    }
   ],
   "source": [
    "slc = SLClassifiers(X_sm, y_sm)\n",
    "\n",
    "dt = slc.decision_tree()\n",
    "rf = slc.random_forest(n_estimators=100)\n",
    "svm = slc.support_vector_machine()\n",
    "knn = slc.k_nearest_neighbours()\n",
    "gnb = slc.gaussian_naive_bayes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Unsupervised Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a class with all the unsupervised learning models to make evaluating them easier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ULClassifiers():\n",
    "    \n",
    "    def __init__(self, X, y): \n",
    "\n",
    "        self.X = X\n",
    "        self.y = y \n",
    "        \n",
    "        \n",
    "    def mask(self, clusters): \n",
    "        \n",
    "        labels = np.zeros_like(clusters)\n",
    "\n",
    "        for i in range(3): \n",
    "            mask = (clusters == i)\n",
    "            labels[mask] = mode(self.y[mask])[0]\n",
    "        \n",
    "        return labels\n",
    "    \n",
    "    \n",
    "    def PCA(self, n=2): \n",
    "        \n",
    "        pca = PCA(n_components=n)\n",
    "        pca.fit(self.X)\n",
    "        X_pca = pca.transform(self.X)\n",
    "        \n",
    "        return X_pca\n",
    "\n",
    "    \n",
    "    def gaussian_mixture_models(self, n=3):\n",
    "        \n",
    "        gmm = GaussianMixture(n_components=n).fit(self.X)\n",
    "        clusters = gmm.predict(self.X)\n",
    "        labels = self.mask(clusters)\n",
    "        print(\"Gaussian Mixture Models accuracy: %.2f\" % accuracy_score(self.y, labels))\n",
    "        \n",
    "    \n",
    "    def k_means(self, n=3, rs=0):\n",
    "    \n",
    "        km = KMeans(n_clusters=n, random_state=rs)\n",
    "        clusters = km.fit_predict(self.X)\n",
    "        labels = self.mask(clusters)\n",
    "        print(\"k Means accuracy: %.2f\" % accuracy_score(self.y, labels))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply all the unsupervised learning models to our raw data to see how well the classifiers perform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Mixture Models accuracy: 0.78\n",
      "k Means accuracy: 0.78\n"
     ]
    }
   ],
   "source": [
    "ulc = ULClassifiers(X, y)\n",
    "\n",
    "gmm = ulc.gaussian_mixture_models()\n",
    "km = ulc.k_means()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we apply all the unsupervised learning models to the processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Mixture Models accuracy: 0.68\n",
      "k Means accuracy: 0.71\n"
     ]
    }
   ],
   "source": [
    "ulc = ULClassifiers(X_sm, y_sm)\n",
    "\n",
    "gmm = ulc.gaussian_mixture_models()\n",
    "km = ulc.k_means()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Future work: hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we evaluated the SL models, the results showed that random forest is the best. In this case, we get an accuracy of `0.98`. If the results had been lower, now would be the time to perform hyperparameter tuning to optimize it even further. \n",
    "\n",
    "**Note**: this is a simplistic approach since we do not know the optimal model architecture for the rest of the models. Thus, a hyper-parameter configuration for one of the other models might render better results than the Random Forest Classifier. However, investing time in finding all the different possible configurations for every model deviated from the objective of our analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at how hyperparameter tuning would look like for the Random Forest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest hyperparameters**:\n",
    "\n",
    "1. `max_dept`: longest path between the root node and the leaf node.\n",
    "2. `min_sample_split`: minimum required number of observations in any given node to split it.\n",
    "3. `max_leaf_nodes`: restricts the growth of the tree.\n",
    "4. `min_samples_leaf`: minimum number of samples that should be present in the leaf node after splitting a node.\n",
    "5. `n_estimators`: Number of trees in the forest.\n",
    "6. `max_sample`: fraction of the original dataset is given to any individual tree.\n",
    "7. `max_features`: number of maximum features provided to each tree in a random forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A way to hyperparameter tune is using GridSearch. \n",
    "\n",
    "The computational complexity of a hyperparameter tuning job depends primarily on the number of hyperparameters whose range of values GridSearch has to search through during optimization. That is why we limit our search to the parameters we think will give us better results.\n",
    "\n",
    "These are: \n",
    "\n",
    "- `n_estimator`: by building forests with a large number of trees (high number of estimators), we can create a more robust model with less variance at the cost of a greater training time. \n",
    "- `criterion`: fine-tuning the split criteria could lead to different forests. Since there are only two possible values, we will try both measures to see which leads to a more minor error.\n",
    "- `min_samples_split`: fine-tuning the number of features to consider when splitting at each node is fundamental. Therefore it should be considered when using a search approach to find the best hyperparameters for our forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block shows how to hyperparmeter tune using grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the important parameters.\n",
    "grid_param = {\n",
    "'n_estimators': [90, 100, 115, 130], \n",
    "'criterion': ['gini', 'entropy'], \n",
    "'min_samples_split': range(1, 10, 1),\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=grid_param, cv=5, verbose=0)\n",
    "\n",
    "# feed the training data set to grid_search\n",
    "## grid_search.fit(X_train, y_train)\n",
    "\n",
    "# to see the best parameters as per our grid\n",
    "## grid_search.best_param_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
